{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q1_cheetah_n500_arch1x32_cheetah-cs285-v0_02-11-2020_17-25-07 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q1_cheetah_n500_arch1x32_cheetah-cs285-v0_02-11-2020_17-25-07\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20040 / 20000\n",
      "Training agent...\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q1_cheetah_n500_arch1x32 --env_name cheetah-cs285-v0 \\\n",
    "--add_sl_noise --n_iter 1 --batch_size_initial 20000 --num_agent_train_steps_per_iter 500 \\\n",
    "--n_layers 1 --size 32 --scalar_log_freq -1 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q1_cheetah_n5_arch2x250_cheetah-cs285-v0_02-11-2020_17-26-04 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q1_cheetah_n5_arch2x250_cheetah-cs285-v0_02-11-2020_17-26-04\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20040 / 20000\n",
      "Training agent...\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q1_cheetah_n5_arch2x250 --env_name cheetah-cs285-v0 \\\n",
    "--add_sl_noise --n_iter 1 --batch_size_initial 20000 --num_agent_train_steps_per_iter 5 \\\n",
    "--n_layers 2 --size 250 --scalar_log_freq -1 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q1_cheetah_n500_arch2x250_cheetah-cs285-v0_02-11-2020_17-26-12 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q1_cheetah_n500_arch2x250_cheetah-cs285-v0_02-11-2020_17-26-12\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20040 / 20000\n",
      "Training agent...\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q1_cheetah_n500_arch2x250 --env_name cheetah-cs285-v0 \\\n",
    "--add_sl_noise --n_iter 1 --batch_size_initial 20000 --num_agent_train_steps_per_iter 500 \\\n",
    "--n_layers 2 --size 250 --scalar_log_freq -1 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q2_obstacles_singleiteration_obstacles-cs285-v0_03-11-2020_18-37-25 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q2_obstacles_singleiteration_obstacles-cs285-v0_03-11-2020_18-37-25\n",
      "########################\n",
      "Using GPU id 0\n",
      "/home/tomas/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5050 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -30.263151168823242\n",
      "Eval_StdReturn : 24.481287002563477\n",
      "Eval_MaxReturn : -12.71245002746582\n",
      "Eval_MinReturn : -108.70587158203125\n",
      "Eval_AverageEpLen : 31.076923076923077\n",
      "Train_AverageReturn : -163.6405487060547\n",
      "Train_StdReturn : 34.4285888671875\n",
      "Train_MaxReturn : -90.67053985595703\n",
      "Train_MinReturn : -227.8916473388672\n",
      "Train_AverageEpLen : 101.0\n",
      "Train_EnvstepsSoFar : 5050\n",
      "TimeSinceStart : 9.798416137695312\n",
      "Training Loss : 0.3172035217285156\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q2_obstacles_singleiteration \\\n",
    "--env_name obstacles-cs285-v0 --add_sl_noise --num_agent_train_steps_per_iter 20 \\\n",
    "--n_iter 1 --batch_size_initial 5000 --batch_size 1000 --mpc_horizon 10 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q3_obstacles_obstacles-cs285-v0_03-11-2020_11-26-50 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q3_obstacles_obstacles-cs285-v0_03-11-2020_11-26-50\n",
      "########################\n",
      "Using GPU id 0\n",
      "/home/tomas/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5050 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -30.263151168823242\n",
      "Eval_StdReturn : 24.481287002563477\n",
      "Eval_MaxReturn : -12.71245002746582\n",
      "Eval_MinReturn : -108.70587158203125\n",
      "Eval_AverageEpLen : 31.076923076923077\n",
      "Train_AverageReturn : -163.6405487060547\n",
      "Train_StdReturn : 34.4285888671875\n",
      "Train_MaxReturn : -90.67053985595703\n",
      "Train_MinReturn : -227.8916473388672\n",
      "Train_AverageEpLen : 101.0\n",
      "Train_EnvstepsSoFar : 5050\n",
      "TimeSinceStart : 9.70091986656189\n",
      "Training Loss : 0.3172035217285156\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1016 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -26.98493766784668\n",
      "Eval_StdReturn : 19.012510299682617\n",
      "Eval_MaxReturn : -9.171807289123535\n",
      "Eval_MinReturn : -85.61963653564453\n",
      "Eval_AverageEpLen : 28.533333333333335\n",
      "Train_AverageReturn : -56.69278335571289\n",
      "Train_StdReturn : 64.79425811767578\n",
      "Train_MaxReturn : -8.476840019226074\n",
      "Train_MinReturn : -188.48545837402344\n",
      "Train_AverageEpLen : 42.333333333333336\n",
      "Train_EnvstepsSoFar : 6066\n",
      "TimeSinceStart : 40.6401252746582\n",
      "Training Loss : 0.3889557421207428\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1014 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -42.927852630615234\n",
      "Eval_StdReturn : 39.1727180480957\n",
      "Eval_MaxReturn : -10.570991516113281\n",
      "Eval_MinReturn : -127.0127182006836\n",
      "Eval_AverageEpLen : 41.45454545454545\n",
      "Train_AverageReturn : -42.6104621887207\n",
      "Train_StdReturn : 47.78700637817383\n",
      "Train_MaxReturn : -8.20486068725586\n",
      "Train_MinReturn : -186.69723510742188\n",
      "Train_AverageEpLen : 36.214285714285715\n",
      "Train_EnvstepsSoFar : 7080\n",
      "TimeSinceStart : 71.49978518486023\n",
      "Training Loss : 0.39618968963623047\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1069 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -41.98633575439453\n",
      "Eval_StdReturn : 29.84848976135254\n",
      "Eval_MaxReturn : -9.57956314086914\n",
      "Eval_MinReturn : -96.36624908447266\n",
      "Eval_AverageEpLen : 41.0\n",
      "Train_AverageReturn : -32.567928314208984\n",
      "Train_StdReturn : 27.71111488342285\n",
      "Train_MaxReturn : -9.191932678222656\n",
      "Train_MinReturn : -99.71170043945312\n",
      "Train_AverageEpLen : 34.483870967741936\n",
      "Train_EnvstepsSoFar : 8149\n",
      "TimeSinceStart : 102.55963015556335\n",
      "Training Loss : 0.39688825607299805\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1005 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -25.390939712524414\n",
      "Eval_StdReturn : 14.333970069885254\n",
      "Eval_MaxReturn : -7.947649955749512\n",
      "Eval_MinReturn : -69.27891540527344\n",
      "Eval_AverageEpLen : 27.333333333333332\n",
      "Train_AverageReturn : -29.357402801513672\n",
      "Train_StdReturn : 26.18572425842285\n",
      "Train_MaxReturn : -8.313626289367676\n",
      "Train_MinReturn : -155.8484344482422\n",
      "Train_AverageEpLen : 30.454545454545453\n",
      "Train_EnvstepsSoFar : 9154\n",
      "TimeSinceStart : 131.70576333999634\n",
      "Training Loss : 0.4039863646030426\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1033 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -32.876522064208984\n",
      "Eval_StdReturn : 31.23786735534668\n",
      "Eval_MaxReturn : -11.452277183532715\n",
      "Eval_MinReturn : -131.42050170898438\n",
      "Eval_AverageEpLen : 32.0\n",
      "Train_AverageReturn : -32.87446212768555\n",
      "Train_StdReturn : 32.47636413574219\n",
      "Train_MaxReturn : -9.120068550109863\n",
      "Train_MinReturn : -183.07861328125\n",
      "Train_AverageEpLen : 31.303030303030305\n",
      "Train_EnvstepsSoFar : 10187\n",
      "TimeSinceStart : 162.55322790145874\n",
      "Training Loss : 0.4069417715072632\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1026 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -24.974376678466797\n",
      "Eval_StdReturn : 14.648033142089844\n",
      "Eval_MaxReturn : -8.357959747314453\n",
      "Eval_MinReturn : -60.211185455322266\n",
      "Eval_AverageEpLen : 26.733333333333334\n",
      "Train_AverageReturn : -27.078834533691406\n",
      "Train_StdReturn : 21.350107192993164\n",
      "Train_MaxReturn : -8.619129180908203\n",
      "Train_MinReturn : -127.470703125\n",
      "Train_AverageEpLen : 27.72972972972973\n",
      "Train_EnvstepsSoFar : 11213\n",
      "TimeSinceStart : 191.77764868736267\n",
      "Training Loss : 0.4015129506587982\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1010 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -28.73512077331543\n",
      "Eval_StdReturn : 18.74089241027832\n",
      "Eval_MaxReturn : -8.496576309204102\n",
      "Eval_MinReturn : -78.26710510253906\n",
      "Eval_AverageEpLen : 31.0\n",
      "Train_AverageReturn : -39.596160888671875\n",
      "Train_StdReturn : 32.045989990234375\n",
      "Train_MaxReturn : -8.489358901977539\n",
      "Train_MinReturn : -147.63780212402344\n",
      "Train_AverageEpLen : 37.407407407407405\n",
      "Train_EnvstepsSoFar : 12223\n",
      "TimeSinceStart : 220.35591316223145\n",
      "Training Loss : 0.4178837239742279\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1001 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -22.16809844970703\n",
      "Eval_StdReturn : 14.804327964782715\n",
      "Eval_MaxReturn : -9.784408569335938\n",
      "Eval_MinReturn : -75.53021240234375\n",
      "Eval_AverageEpLen : 25.625\n",
      "Train_AverageReturn : -28.869924545288086\n",
      "Train_StdReturn : 18.033903121948242\n",
      "Train_MaxReturn : -9.085773468017578\n",
      "Train_MinReturn : -73.11389923095703\n",
      "Train_AverageEpLen : 29.441176470588236\n",
      "Train_EnvstepsSoFar : 13224\n",
      "TimeSinceStart : 249.17134022712708\n",
      "Training Loss : 0.41433966159820557\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1017 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -36.426109313964844\n",
      "Eval_StdReturn : 39.40607452392578\n",
      "Eval_MaxReturn : -10.757561683654785\n",
      "Eval_MinReturn : -168.7849884033203\n",
      "Eval_AverageEpLen : 32.69230769230769\n",
      "Train_AverageReturn : -27.2613582611084\n",
      "Train_StdReturn : 25.32721519470215\n",
      "Train_MaxReturn : -8.65611743927002\n",
      "Train_MinReturn : -160.64520263671875\n",
      "Train_AverageEpLen : 27.486486486486488\n",
      "Train_EnvstepsSoFar : 14241\n",
      "TimeSinceStart : 278.3020384311676\n",
      "Training Loss : 0.4001959264278412\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1010 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -26.7607364654541\n",
      "Eval_StdReturn : 12.489225387573242\n",
      "Eval_MaxReturn : -12.256064414978027\n",
      "Eval_MinReturn : -58.77938461303711\n",
      "Eval_AverageEpLen : 27.466666666666665\n",
      "Train_AverageReturn : -30.347021102905273\n",
      "Train_StdReturn : 20.668176651000977\n",
      "Train_MaxReturn : -9.470983505249023\n",
      "Train_MinReturn : -102.50846099853516\n",
      "Train_AverageEpLen : 29.705882352941178\n",
      "Train_EnvstepsSoFar : 15251\n",
      "TimeSinceStart : 307.6953225135803\n",
      "Training Loss : 0.4043246805667877\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     1052 / 1000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -30.00228500366211\n",
      "Eval_StdReturn : 31.989564895629883\n",
      "Eval_MaxReturn : -12.322982788085938\n",
      "Eval_MinReturn : -138.97537231445312\n",
      "Eval_AverageEpLen : 29.357142857142858\n",
      "Train_AverageReturn : -31.14488983154297\n",
      "Train_StdReturn : 28.118694305419922\n",
      "Train_MaxReturn : -7.88134241104126\n",
      "Train_MinReturn : -145.6745147705078\n",
      "Train_AverageEpLen : 30.941176470588236\n",
      "Train_EnvstepsSoFar : 16303\n",
      "TimeSinceStart : 338.02959275245667\n",
      "Training Loss : 0.3992149829864502\n",
      "Initial_DataCollection_AverageReturn : -163.6405487060547\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q3_obstacles --env_name obstacles-cs285-v0 \\\n",
    "--add_sl_noise --num_agent_train_steps_per_iter 20 --batch_size_initial 5000 \\\n",
    "--batch_size 1000 --mpc_horizon 10 --n_iter 12 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q3_reacher_reacher-cs285-v0_03-11-2020_11-32-31 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q3_reacher_reacher-cs285-v0_03-11-2020_11-32-31\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -605.682861328125\n",
      "Eval_StdReturn : 129.32162475585938\n",
      "Eval_MaxReturn : -476.36126708984375\n",
      "Eval_MinReturn : -735.0045166015625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1862.00341796875\n",
      "Train_StdReturn : 339.26837158203125\n",
      "Train_MaxReturn : -1258.4478759765625\n",
      "Train_MinReturn : -2519.1728515625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 5025\n",
      "TimeSinceStart : 16.334283351898193\n",
      "Training Loss : 0.15265904366970062\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -299.0442810058594\n",
      "Eval_StdReturn : 2.10443115234375\n",
      "Eval_MaxReturn : -296.9398498535156\n",
      "Eval_MinReturn : -301.1487121582031\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -599.3734130859375\n",
      "Train_StdReturn : 134.4142608642578\n",
      "Train_MaxReturn : -420.3179626464844\n",
      "Train_MinReturn : -934.828125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 10050\n",
      "TimeSinceStart : 146.91671752929688\n",
      "Training Loss : 0.16577307879924774\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -276.6081237792969\n",
      "Eval_StdReturn : 21.82098388671875\n",
      "Eval_MaxReturn : -254.78713989257812\n",
      "Eval_MinReturn : -298.4291076660156\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -319.1991271972656\n",
      "Train_StdReturn : 42.17963409423828\n",
      "Train_MaxReturn : -268.7829895019531\n",
      "Train_MinReturn : -435.85845947265625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 15075\n",
      "TimeSinceStart : 276.5097563266754\n",
      "Training Loss : 0.15867497026920319\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -271.5843811035156\n",
      "Eval_StdReturn : 22.558631896972656\n",
      "Eval_MaxReturn : -249.02574157714844\n",
      "Eval_MinReturn : -294.14300537109375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -282.8837890625\n",
      "Train_StdReturn : 16.886341094970703\n",
      "Train_MaxReturn : -256.1281433105469\n",
      "Train_MinReturn : -321.1039123535156\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 403.3323984146118\n",
      "Training Loss : 0.15723486244678497\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -278.128662109375\n",
      "Eval_StdReturn : 1.87738037109375\n",
      "Eval_MaxReturn : -276.25128173828125\n",
      "Eval_MinReturn : -280.00604248046875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -271.1894836425781\n",
      "Train_StdReturn : 20.02543067932129\n",
      "Train_MaxReturn : -241.13824462890625\n",
      "Train_MinReturn : -320.9846496582031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25125\n",
      "TimeSinceStart : 531.5942840576172\n",
      "Training Loss : 0.1520235687494278\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -280.2140197753906\n",
      "Eval_StdReturn : 6.7572021484375\n",
      "Eval_MaxReturn : -273.4568176269531\n",
      "Eval_MinReturn : -286.9712219238281\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -262.7005310058594\n",
      "Train_StdReturn : 13.372441291809082\n",
      "Train_MaxReturn : -243.57302856445312\n",
      "Train_MinReturn : -297.7127685546875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30150\n",
      "TimeSinceStart : 656.8261349201202\n",
      "Training Loss : 0.14431132376194\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -247.96746826171875\n",
      "Eval_StdReturn : 2.9908828735351562\n",
      "Eval_MaxReturn : -244.97659301757812\n",
      "Eval_MinReturn : -250.95835876464844\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -260.98614501953125\n",
      "Train_StdReturn : 19.393617630004883\n",
      "Train_MaxReturn : -231.83241271972656\n",
      "Train_MinReturn : -323.15570068359375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 35175\n",
      "TimeSinceStart : 782.3623764514923\n",
      "Training Loss : 0.14183974266052246\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -270.7786865234375\n",
      "Eval_StdReturn : 1.6764678955078125\n",
      "Eval_MaxReturn : -269.1022033691406\n",
      "Eval_MinReturn : -272.45513916015625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -262.4936218261719\n",
      "Train_StdReturn : 16.86319923400879\n",
      "Train_MaxReturn : -242.25450134277344\n",
      "Train_MinReturn : -309.5491027832031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 40200\n",
      "TimeSinceStart : 908.9558863639832\n",
      "Training Loss : 0.14068050682544708\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -257.3555603027344\n",
      "Eval_StdReturn : 6.174812316894531\n",
      "Eval_MaxReturn : -251.1807403564453\n",
      "Eval_MinReturn : -263.5303649902344\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -259.60015869140625\n",
      "Train_StdReturn : 16.24683952331543\n",
      "Train_MaxReturn : -233.52037048339844\n",
      "Train_MinReturn : -307.00592041015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 45225\n",
      "TimeSinceStart : 1036.1110210418701\n",
      "Training Loss : 0.1416001170873642\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -269.86175537109375\n",
      "Eval_StdReturn : 7.3574676513671875\n",
      "Eval_MaxReturn : -262.5042724609375\n",
      "Eval_MinReturn : -277.2192077636719\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -262.16192626953125\n",
      "Train_StdReturn : 18.392473220825195\n",
      "Train_MaxReturn : -240.22903442382812\n",
      "Train_MinReturn : -315.2347106933594\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 50250\n",
      "TimeSinceStart : 1160.794117450714\n",
      "Training Loss : 0.14188282191753387\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -272.25006103515625\n",
      "Eval_StdReturn : 5.5290374755859375\n",
      "Eval_MaxReturn : -266.7210388183594\n",
      "Eval_MinReturn : -277.77911376953125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -263.19793701171875\n",
      "Train_StdReturn : 11.68635082244873\n",
      "Train_MaxReturn : -244.1927032470703\n",
      "Train_MinReturn : -293.8415222167969\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 55275\n",
      "TimeSinceStart : 1285.5494918823242\n",
      "Training Loss : 0.13415981829166412\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -243.76544189453125\n",
      "Eval_StdReturn : 2.7324752807617188\n",
      "Eval_MaxReturn : -241.03297424316406\n",
      "Eval_MinReturn : -246.4979248046875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -256.2752380371094\n",
      "Train_StdReturn : 16.161861419677734\n",
      "Train_MaxReturn : -226.49710083007812\n",
      "Train_MinReturn : -290.1374206542969\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 60300\n",
      "TimeSinceStart : 1410.3613233566284\n",
      "Training Loss : 0.13059693574905396\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -256.28912353515625\n",
      "Eval_StdReturn : 8.481094360351562\n",
      "Eval_MaxReturn : -247.80804443359375\n",
      "Eval_MinReturn : -264.7702331542969\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -261.3009948730469\n",
      "Train_StdReturn : 21.20271110534668\n",
      "Train_MaxReturn : -228.14736938476562\n",
      "Train_MinReturn : -330.4133605957031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 65325\n",
      "TimeSinceStart : 1534.6274127960205\n",
      "Training Loss : 0.13145864009857178\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -257.6131286621094\n",
      "Eval_StdReturn : 5.298881530761719\n",
      "Eval_MaxReturn : -252.3142547607422\n",
      "Eval_MinReturn : -262.9120178222656\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -261.5928039550781\n",
      "Train_StdReturn : 14.840330123901367\n",
      "Train_MaxReturn : -236.44534301757812\n",
      "Train_MinReturn : -300.0523986816406\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 70350\n",
      "TimeSinceStart : 1660.5262699127197\n",
      "Training Loss : 0.12835225462913513\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5025 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -268.4280090332031\n",
      "Eval_StdReturn : 8.1441650390625\n",
      "Eval_MaxReturn : -260.2838439941406\n",
      "Eval_MinReturn : -276.5721740722656\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -258.3509826660156\n",
      "Train_StdReturn : 13.248597145080566\n",
      "Train_MaxReturn : -234.12667846679688\n",
      "Train_MinReturn : -281.4584045410156\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 75375\n",
      "TimeSinceStart : 1787.2706007957458\n",
      "Training Loss : 0.12317222356796265\n",
      "Initial_DataCollection_AverageReturn : -1862.00341796875\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q3_reacher --env_name reacher-cs285-v0 \\\n",
    "--add_sl_noise --mpc_horizon 10 --num_agent_train_steps_per_iter 1000 \\\n",
    "--batch_size_initial 5000 --batch_size 5000 --n_iter 15 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q3_cheetah_cheetah-cs285-v0_03-11-2020_12-02-21 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q3_cheetah_cheetah-cs285-v0_03-11-2020_12-02-21\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 68.93409729003906\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 68.93409729003906\n",
      "Eval_MinReturn : 68.93409729003906\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : -2493.047607421875\n",
      "Train_StdReturn : 329.61224365234375\n",
      "Train_MaxReturn : -1978.490966796875\n",
      "Train_MinReturn : -3080.7255859375\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 5010\n",
      "TimeSinceStart : 25.58046817779541\n",
      "Training Loss : 0.07422281056642532\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 206.4495849609375\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 206.4495849609375\n",
      "Eval_MinReturn : 206.4495849609375\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 97.09542083740234\n",
      "Train_StdReturn : 13.274174690246582\n",
      "Train_MaxReturn : 117.17227172851562\n",
      "Train_MinReturn : 78.76559448242188\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 10020\n",
      "TimeSinceStart : 216.89780688285828\n",
      "Training Loss : 0.09270403534173965\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 263.0824890136719\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 263.0824890136719\n",
      "Eval_MinReturn : 263.0824890136719\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 189.37550354003906\n",
      "Train_StdReturn : 27.157304763793945\n",
      "Train_MaxReturn : 239.7430877685547\n",
      "Train_MinReturn : 152.4503631591797\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 15030\n",
      "TimeSinceStart : 405.25172781944275\n",
      "Training Loss : 0.09663917869329453\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 296.23223876953125\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 296.23223876953125\n",
      "Eval_MinReturn : 296.23223876953125\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 238.15475463867188\n",
      "Train_StdReturn : 31.384836196899414\n",
      "Train_MaxReturn : 294.7395935058594\n",
      "Train_MinReturn : 200.0164031982422\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 20040\n",
      "TimeSinceStart : 593.516802072525\n",
      "Training Loss : 0.10329554229974747\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 263.8831787109375\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 263.8831787109375\n",
      "Eval_MinReturn : 263.8831787109375\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 267.0404968261719\n",
      "Train_StdReturn : 21.75090789794922\n",
      "Train_MaxReturn : 290.189453125\n",
      "Train_MinReturn : 221.2375030517578\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 25050\n",
      "TimeSinceStart : 783.1421205997467\n",
      "Training Loss : 0.09603551030158997\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 238.93429565429688\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 238.93429565429688\n",
      "Eval_MinReturn : 238.93429565429688\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 298.3130798339844\n",
      "Train_StdReturn : 38.06144332885742\n",
      "Train_MaxReturn : 357.07073974609375\n",
      "Train_MinReturn : 215.85275268554688\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 30060\n",
      "TimeSinceStart : 973.6569464206696\n",
      "Training Loss : 0.10141365975141525\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 276.2686462402344\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 276.2686462402344\n",
      "Eval_MinReturn : 276.2686462402344\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 275.9920654296875\n",
      "Train_StdReturn : 42.38080596923828\n",
      "Train_MaxReturn : 353.380126953125\n",
      "Train_MinReturn : 194.8487091064453\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 35070\n",
      "TimeSinceStart : 1162.5258407592773\n",
      "Training Loss : 0.1047256588935852\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 285.81683349609375\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 285.81683349609375\n",
      "Eval_MinReturn : 285.81683349609375\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 274.8773498535156\n",
      "Train_StdReturn : 21.421396255493164\n",
      "Train_MaxReturn : 309.9698486328125\n",
      "Train_MinReturn : 240.75723266601562\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 40080\n",
      "TimeSinceStart : 1352.9640715122223\n",
      "Training Loss : 0.10344243794679642\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 315.5781555175781\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 315.5781555175781\n",
      "Eval_MinReturn : 315.5781555175781\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 323.43505859375\n",
      "Train_StdReturn : 32.37376403808594\n",
      "Train_MaxReturn : 365.92852783203125\n",
      "Train_MinReturn : 262.39678955078125\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 45090\n",
      "TimeSinceStart : 1543.5305843353271\n",
      "Training Loss : 0.10582416504621506\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 376.81787109375\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 376.81787109375\n",
      "Eval_MinReturn : 376.81787109375\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 308.07965087890625\n",
      "Train_StdReturn : 28.452821731567383\n",
      "Train_MaxReturn : 353.093994140625\n",
      "Train_MinReturn : 270.48309326171875\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 50100\n",
      "TimeSinceStart : 1734.9814946651459\n",
      "Training Loss : 0.10721591114997864\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 347.486328125\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 347.486328125\n",
      "Eval_MinReturn : 347.486328125\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 319.7183532714844\n",
      "Train_StdReturn : 51.067771911621094\n",
      "Train_MaxReturn : 455.1197204589844\n",
      "Train_MinReturn : 269.0673828125\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 55110\n",
      "TimeSinceStart : 1926.034656047821\n",
      "Training Loss : 0.10457306355237961\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 251.20425415039062\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 251.20425415039062\n",
      "Eval_MinReturn : 251.20425415039062\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 324.5324401855469\n",
      "Train_StdReturn : 36.50569152832031\n",
      "Train_MaxReturn : 387.5811462402344\n",
      "Train_MinReturn : 269.4285583496094\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 60120\n",
      "TimeSinceStart : 2118.1486206054688\n",
      "Training Loss : 0.10384450107812881\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 398.6524658203125\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 398.6524658203125\n",
      "Eval_MinReturn : 398.6524658203125\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 344.6550598144531\n",
      "Train_StdReturn : 38.26543045043945\n",
      "Train_MaxReturn : 418.35693359375\n",
      "Train_MinReturn : 299.0660400390625\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 65130\n",
      "TimeSinceStart : 2310.8397784233093\n",
      "Training Loss : 0.10489942878484726\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 302.43524169921875\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 302.43524169921875\n",
      "Eval_MinReturn : 302.43524169921875\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 313.38458251953125\n",
      "Train_StdReturn : 39.20369338989258\n",
      "Train_MaxReturn : 399.754150390625\n",
      "Train_MinReturn : 278.070556640625\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 70140\n",
      "TimeSinceStart : 2501.314211368561\n",
      "Training Loss : 0.10464587062597275\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 291.9524230957031\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 291.9524230957031\n",
      "Eval_MinReturn : 291.9524230957031\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 317.935546875\n",
      "Train_StdReturn : 29.62355613708496\n",
      "Train_MaxReturn : 354.3619384765625\n",
      "Train_MinReturn : 250.53326416015625\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 75150\n",
      "TimeSinceStart : 2699.4692265987396\n",
      "Training Loss : 0.10312537103891373\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 309.16595458984375\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 309.16595458984375\n",
      "Eval_MinReturn : 309.16595458984375\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 304.94903564453125\n",
      "Train_StdReturn : 40.40235900878906\n",
      "Train_MaxReturn : 394.64599609375\n",
      "Train_MinReturn : 255.97723388671875\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 80160\n",
      "TimeSinceStart : 2887.132192850113\n",
      "Training Loss : 0.10648823529481888\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 237.39471435546875\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 237.39471435546875\n",
      "Eval_MinReturn : 237.39471435546875\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 324.33233642578125\n",
      "Train_StdReturn : 24.654491424560547\n",
      "Train_MaxReturn : 358.1094970703125\n",
      "Train_MinReturn : 284.1019287109375\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 85170\n",
      "TimeSinceStart : 3074.557544231415\n",
      "Training Loss : 0.10465598106384277\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 392.17791748046875\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 392.17791748046875\n",
      "Eval_MinReturn : 392.17791748046875\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 299.9805908203125\n",
      "Train_StdReturn : 30.104534149169922\n",
      "Train_MaxReturn : 374.911865234375\n",
      "Train_MinReturn : 261.83837890625\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 90180\n",
      "TimeSinceStart : 3261.3087916374207\n",
      "Training Loss : 0.10533851385116577\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 284.08258056640625\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 284.08258056640625\n",
      "Eval_MinReturn : 284.08258056640625\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 314.7228088378906\n",
      "Train_StdReturn : 34.29292678833008\n",
      "Train_MaxReturn : 375.8516845703125\n",
      "Train_MinReturn : 248.91726684570312\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 95190\n",
      "TimeSinceStart : 3448.476226091385\n",
      "Training Loss : 0.10173654556274414\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     5010 / 5000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 393.09149169921875\n",
      "Eval_StdReturn : 0.0\n",
      "Eval_MaxReturn : 393.09149169921875\n",
      "Eval_MinReturn : 393.09149169921875\n",
      "Eval_AverageEpLen : 501.0\n",
      "Train_AverageReturn : 337.4634094238281\n",
      "Train_StdReturn : 33.73931884765625\n",
      "Train_MaxReturn : 387.080078125\n",
      "Train_MinReturn : 284.4800720214844\n",
      "Train_AverageEpLen : 501.0\n",
      "Train_EnvstepsSoFar : 100200\n",
      "TimeSinceStart : 3636.8264870643616\n",
      "Training Loss : 0.10320824384689331\n",
      "Initial_DataCollection_AverageReturn : -2493.047607421875\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q3_cheetah --env_name cheetah-cs285-v0 \\\n",
    "--mpc_horizon 15 --add_sl_noise --num_agent_train_steps_per_iter 1500 \\\n",
    "--batch_size_initial 5000 --batch_size 5000 --n_iter 20 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon5_reacher-cs285-v0_03-11-2020_18-37-40 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon5_reacher-cs285-v0_03-11-2020_18-37-40\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20100 / 20000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -646.0748291015625\n",
      "Eval_StdReturn : 60.288543701171875\n",
      "Eval_MaxReturn : -585.7863159179688\n",
      "Eval_MinReturn : -706.3634033203125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1887.6396484375\n",
      "Train_StdReturn : 406.19140625\n",
      "Train_MaxReturn : -943.790283203125\n",
      "Train_MinReturn : -2592.39208984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 13.075472354888916\n",
      "Training Loss : 0.19842225313186646\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -418.6077880859375\n",
      "Eval_StdReturn : 141.29246520996094\n",
      "Eval_MaxReturn : -277.3153381347656\n",
      "Eval_MinReturn : -559.9002685546875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -958.520751953125\n",
      "Train_StdReturn : 280.63446044921875\n",
      "Train_MaxReturn : -588.4509887695312\n",
      "Train_MinReturn : -1337.873779296875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20904\n",
      "TimeSinceStart : 32.504143476486206\n",
      "Training Loss : 0.18054990470409393\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -285.5421142578125\n",
      "Eval_StdReturn : 21.519027709960938\n",
      "Eval_MaxReturn : -264.0231018066406\n",
      "Eval_MinReturn : -307.0611572265625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -299.8941650390625\n",
      "Train_StdReturn : 13.743535041809082\n",
      "Train_MaxReturn : -276.6170349121094\n",
      "Train_MinReturn : -310.3171081542969\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 21708\n",
      "TimeSinceStart : 53.363314390182495\n",
      "Training Loss : 0.1674836277961731\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -270.09405517578125\n",
      "Eval_StdReturn : 14.033935546875\n",
      "Eval_MaxReturn : -256.06011962890625\n",
      "Eval_MinReturn : -284.12799072265625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -273.80712890625\n",
      "Train_StdReturn : 28.082948684692383\n",
      "Train_MaxReturn : -247.50924682617188\n",
      "Train_MinReturn : -316.496337890625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 22512\n",
      "TimeSinceStart : 72.86497163772583\n",
      "Training Loss : 0.16959631443023682\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -271.91729736328125\n",
      "Eval_StdReturn : 9.6895751953125\n",
      "Eval_MaxReturn : -262.22772216796875\n",
      "Eval_MinReturn : -281.60687255859375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -295.9316101074219\n",
      "Train_StdReturn : 80.08646392822266\n",
      "Train_MaxReturn : -243.10006713867188\n",
      "Train_MinReturn : -434.143310546875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 23316\n",
      "TimeSinceStart : 92.23502564430237\n",
      "Training Loss : 0.17608727514743805\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -277.0964660644531\n",
      "Eval_StdReturn : 4.603851318359375\n",
      "Eval_MaxReturn : -272.49261474609375\n",
      "Eval_MinReturn : -281.7003173828125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -564.9840087890625\n",
      "Train_StdReturn : 292.9741516113281\n",
      "Train_MaxReturn : -274.42388916015625\n",
      "Train_MinReturn : -927.519775390625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24120\n",
      "TimeSinceStart : 111.81197786331177\n",
      "Training Loss : 0.16090025007724762\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -277.3817138671875\n",
      "Eval_StdReturn : 2.3274688720703125\n",
      "Eval_MaxReturn : -275.0542297363281\n",
      "Eval_MinReturn : -279.70916748046875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -310.74700927734375\n",
      "Train_StdReturn : 55.06660842895508\n",
      "Train_MaxReturn : -259.5216979980469\n",
      "Train_MinReturn : -403.10662841796875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24924\n",
      "TimeSinceStart : 131.09313702583313\n",
      "Training Loss : 0.15261010825634003\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -243.26080322265625\n",
      "Eval_StdReturn : 6.088676452636719\n",
      "Eval_MaxReturn : -237.172119140625\n",
      "Eval_MinReturn : -249.34947204589844\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -307.7366027832031\n",
      "Train_StdReturn : 61.63816452026367\n",
      "Train_MaxReturn : -249.16773986816406\n",
      "Train_MinReturn : -400.9892578125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25728\n",
      "TimeSinceStart : 150.82564187049866\n",
      "Training Loss : 0.1535874456167221\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -254.38641357421875\n",
      "Eval_StdReturn : 3.8199539184570312\n",
      "Eval_MaxReturn : -250.5664520263672\n",
      "Eval_MinReturn : -258.20635986328125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -258.5128479003906\n",
      "Train_StdReturn : 13.81260871887207\n",
      "Train_MaxReturn : -241.4154510498047\n",
      "Train_MinReturn : -277.50079345703125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 26532\n",
      "TimeSinceStart : 170.4862985610962\n",
      "Training Loss : 0.155539408326149\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -258.57275390625\n",
      "Eval_StdReturn : 5.180274963378906\n",
      "Eval_MaxReturn : -253.39247131347656\n",
      "Eval_MinReturn : -263.7530212402344\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -264.0820007324219\n",
      "Train_StdReturn : 16.03276824951172\n",
      "Train_MaxReturn : -249.68333435058594\n",
      "Train_MinReturn : -290.138916015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 27336\n",
      "TimeSinceStart : 189.93975162506104\n",
      "Training Loss : 0.1515786498785019\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -301.93194580078125\n",
      "Eval_StdReturn : 24.133346557617188\n",
      "Eval_MaxReturn : -277.798583984375\n",
      "Eval_MinReturn : -326.0652770996094\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -275.53643798828125\n",
      "Train_StdReturn : 27.28493881225586\n",
      "Train_MaxReturn : -242.05039978027344\n",
      "Train_MinReturn : -317.41607666015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28140\n",
      "TimeSinceStart : 210.56053400039673\n",
      "Training Loss : 0.1621636301279068\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -277.41632080078125\n",
      "Eval_StdReturn : 23.127944946289062\n",
      "Eval_MaxReturn : -254.28839111328125\n",
      "Eval_MinReturn : -300.5442810058594\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -290.49627685546875\n",
      "Train_StdReturn : 31.693117141723633\n",
      "Train_MaxReturn : -260.3558654785156\n",
      "Train_MinReturn : -338.3236083984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28944\n",
      "TimeSinceStart : 231.2561583518982\n",
      "Training Loss : 0.15149056911468506\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -267.91571044921875\n",
      "Eval_StdReturn : 20.473007202148438\n",
      "Eval_MaxReturn : -247.44271850585938\n",
      "Eval_MinReturn : -288.38873291015625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -260.30548095703125\n",
      "Train_StdReturn : 17.52460479736328\n",
      "Train_MaxReturn : -236.29571533203125\n",
      "Train_MinReturn : -278.604736328125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 29748\n",
      "TimeSinceStart : 251.69628953933716\n",
      "Training Loss : 0.15166227519512177\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -272.37152099609375\n",
      "Eval_StdReturn : 16.68164825439453\n",
      "Eval_MaxReturn : -255.6898651123047\n",
      "Eval_MinReturn : -289.05316162109375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -279.2750244140625\n",
      "Train_StdReturn : 11.306696891784668\n",
      "Train_MaxReturn : -267.09698486328125\n",
      "Train_MinReturn : -292.81768798828125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30552\n",
      "TimeSinceStart : 272.30028891563416\n",
      "Training Loss : 0.14400964975357056\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -254.842529296875\n",
      "Eval_StdReturn : 10.207084655761719\n",
      "Eval_MaxReturn : -244.6354522705078\n",
      "Eval_MinReturn : -265.04962158203125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -247.60400390625\n",
      "Train_StdReturn : 9.120482444763184\n",
      "Train_MaxReturn : -238.79649353027344\n",
      "Train_MinReturn : -259.78790283203125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 31356\n",
      "TimeSinceStart : 292.95475673675537\n",
      "Training Loss : 0.1476292461156845\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q4_reacher_horizon5 --env_name reacher-cs285-v0 \\\n",
    "--add_sl_noise --mpc_horizon 5 --num_agent_train_steps_per_iter 1000 --video_log_freq -1 --batch_size 800 --n_iter 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon15_reacher-cs285-v0_03-11-2020_18-42-36 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon15_reacher-cs285-v0_03-11-2020_18-42-36\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20100 / 20000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -425.666015625\n",
      "Eval_StdReturn : 21.5830078125\n",
      "Eval_MaxReturn : -404.0830078125\n",
      "Eval_MinReturn : -447.2490234375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1887.6396484375\n",
      "Train_StdReturn : 406.19140625\n",
      "Train_MaxReturn : -943.790283203125\n",
      "Train_MinReturn : -2592.39208984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 23.02968144416809\n",
      "Training Loss : 0.19842225313186646\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -329.194580078125\n",
      "Eval_StdReturn : 43.571533203125\n",
      "Eval_MaxReturn : -285.623046875\n",
      "Eval_MinReturn : -372.76611328125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -411.774169921875\n",
      "Train_StdReturn : 31.222047805786133\n",
      "Train_MaxReturn : -376.2611083984375\n",
      "Train_MinReturn : -450.76043701171875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20904\n",
      "TimeSinceStart : 72.07274174690247\n",
      "Training Loss : 0.18546859920024872\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -285.59271240234375\n",
      "Eval_StdReturn : 4.93402099609375\n",
      "Eval_MaxReturn : -280.65869140625\n",
      "Eval_MinReturn : -290.5267333984375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -310.87213134765625\n",
      "Train_StdReturn : 21.161396026611328\n",
      "Train_MaxReturn : -292.9833984375\n",
      "Train_MinReturn : -346.9617004394531\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 21708\n",
      "TimeSinceStart : 120.93962478637695\n",
      "Training Loss : 0.1750836819410324\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -280.64129638671875\n",
      "Eval_StdReturn : 8.138534545898438\n",
      "Eval_MaxReturn : -272.5027770996094\n",
      "Eval_MinReturn : -288.77984619140625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -284.3121643066406\n",
      "Train_StdReturn : 18.329957962036133\n",
      "Train_MaxReturn : -263.7896423339844\n",
      "Train_MinReturn : -310.21533203125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 22512\n",
      "TimeSinceStart : 169.8391752243042\n",
      "Training Loss : 0.17301104962825775\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -260.5823669433594\n",
      "Eval_StdReturn : 1.545013427734375\n",
      "Eval_MaxReturn : -259.037353515625\n",
      "Eval_MinReturn : -262.12738037109375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -283.8108825683594\n",
      "Train_StdReturn : 7.356186866760254\n",
      "Train_MaxReturn : -272.9130554199219\n",
      "Train_MinReturn : -291.81695556640625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 23316\n",
      "TimeSinceStart : 218.67447662353516\n",
      "Training Loss : 0.1696559190750122\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -291.8055419921875\n",
      "Eval_StdReturn : 2.31927490234375\n",
      "Eval_MaxReturn : -289.48626708984375\n",
      "Eval_MinReturn : -294.12481689453125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -293.29107666015625\n",
      "Train_StdReturn : 12.771257400512695\n",
      "Train_MaxReturn : -279.68927001953125\n",
      "Train_MinReturn : -308.8667297363281\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24120\n",
      "TimeSinceStart : 267.45174741744995\n",
      "Training Loss : 0.16948337852954865\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -264.17034912109375\n",
      "Eval_StdReturn : 0.559234619140625\n",
      "Eval_MaxReturn : -263.6111145019531\n",
      "Eval_MinReturn : -264.7295837402344\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -290.42767333984375\n",
      "Train_StdReturn : 5.433671951293945\n",
      "Train_MaxReturn : -283.527587890625\n",
      "Train_MinReturn : -298.0334777832031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24924\n",
      "TimeSinceStart : 316.42519903182983\n",
      "Training Loss : 0.16390644013881683\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -313.2943115234375\n",
      "Eval_StdReturn : 9.223587036132812\n",
      "Eval_MaxReturn : -304.07073974609375\n",
      "Eval_MinReturn : -322.5179138183594\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -285.60736083984375\n",
      "Train_StdReturn : 11.170623779296875\n",
      "Train_MaxReturn : -272.9043884277344\n",
      "Train_MinReturn : -296.7501220703125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25728\n",
      "TimeSinceStart : 365.3394603729248\n",
      "Training Loss : 0.15748529136180878\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -279.6378173828125\n",
      "Eval_StdReturn : 11.236663818359375\n",
      "Eval_MaxReturn : -268.4011535644531\n",
      "Eval_MinReturn : -290.8744812011719\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -277.4391784667969\n",
      "Train_StdReturn : 15.297574996948242\n",
      "Train_MaxReturn : -257.98309326171875\n",
      "Train_MinReturn : -293.6898498535156\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 26532\n",
      "TimeSinceStart : 414.2762408256531\n",
      "Training Loss : 0.1555103361606598\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -289.0529479980469\n",
      "Eval_StdReturn : 10.565826416015625\n",
      "Eval_MaxReturn : -278.48712158203125\n",
      "Eval_MinReturn : -299.6187744140625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -289.638671875\n",
      "Train_StdReturn : 8.518320083618164\n",
      "Train_MaxReturn : -276.27593994140625\n",
      "Train_MinReturn : -299.457763671875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 27336\n",
      "TimeSinceStart : 459.7657616138458\n",
      "Training Loss : 0.15763871371746063\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -344.0340881347656\n",
      "Eval_StdReturn : 46.892486572265625\n",
      "Eval_MaxReturn : -297.1416015625\n",
      "Eval_MinReturn : -390.92657470703125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -277.275390625\n",
      "Train_StdReturn : 4.350478649139404\n",
      "Train_MaxReturn : -269.9724426269531\n",
      "Train_MinReturn : -281.4505310058594\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28140\n",
      "TimeSinceStart : 507.02425050735474\n",
      "Training Loss : 0.15794070065021515\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -278.36761474609375\n",
      "Eval_StdReturn : 7.9033050537109375\n",
      "Eval_MaxReturn : -270.46429443359375\n",
      "Eval_MinReturn : -286.2709045410156\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -300.0771789550781\n",
      "Train_StdReturn : 36.82691192626953\n",
      "Train_MaxReturn : -264.97491455078125\n",
      "Train_MinReturn : -357.0711364746094\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28944\n",
      "TimeSinceStart : 555.8269376754761\n",
      "Training Loss : 0.149705708026886\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -291.88653564453125\n",
      "Eval_StdReturn : 10.72686767578125\n",
      "Eval_MaxReturn : -281.15966796875\n",
      "Eval_MinReturn : -302.6134033203125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -312.6962585449219\n",
      "Train_StdReturn : 20.224769592285156\n",
      "Train_MaxReturn : -293.1471252441406\n",
      "Train_MinReturn : -344.1972351074219\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 29748\n",
      "TimeSinceStart : 604.4140086174011\n",
      "Training Loss : 0.15078026056289673\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -299.1684265136719\n",
      "Eval_StdReturn : 3.389617919921875\n",
      "Eval_MaxReturn : -295.77880859375\n",
      "Eval_MinReturn : -302.55804443359375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -267.76824951171875\n",
      "Train_StdReturn : 10.561643600463867\n",
      "Train_MaxReturn : -257.2884521484375\n",
      "Train_MinReturn : -281.2513732910156\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30552\n",
      "TimeSinceStart : 653.6684591770172\n",
      "Training Loss : 0.14904652535915375\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -322.3128662109375\n",
      "Eval_StdReturn : 18.136184692382812\n",
      "Eval_MaxReturn : -304.1766662597656\n",
      "Eval_MinReturn : -340.44903564453125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -283.4608154296875\n",
      "Train_StdReturn : 8.589399337768555\n",
      "Train_MaxReturn : -272.0060729980469\n",
      "Train_MinReturn : -295.9297180175781\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 31356\n",
      "TimeSinceStart : 703.2306091785431\n",
      "Training Loss : 0.1505044847726822\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q4_reacher_horizon15 --env_name reacher-cs285-v0 \\\n",
    "--add_sl_noise --mpc_horizon 15 --num_agent_train_steps_per_iter 1000 --video_log_freq -1 --batch_size 800 --n_iter 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon30_reacher-cs285-v0_03-11-2020_18-54-22 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon30_reacher-cs285-v0_03-11-2020_18-54-22\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20100 / 20000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -459.35540771484375\n",
      "Eval_StdReturn : 3.5224609375\n",
      "Eval_MaxReturn : -455.83294677734375\n",
      "Eval_MinReturn : -462.87786865234375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1887.6396484375\n",
      "Train_StdReturn : 406.19140625\n",
      "Train_MaxReturn : -943.790283203125\n",
      "Train_MinReturn : -2592.39208984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 38.16323804855347\n",
      "Training Loss : 0.19842225313186646\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -375.5738525390625\n",
      "Eval_StdReturn : 38.642974853515625\n",
      "Eval_MaxReturn : -336.9308776855469\n",
      "Eval_MinReturn : -414.2168273925781\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -433.183349609375\n",
      "Train_StdReturn : 43.860008239746094\n",
      "Train_MaxReturn : -369.32861328125\n",
      "Train_MinReturn : -492.064453125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20904\n",
      "TimeSinceStart : 129.28111791610718\n",
      "Training Loss : 0.18424175679683685\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -336.14910888671875\n",
      "Eval_StdReturn : 6.5589447021484375\n",
      "Eval_MaxReturn : -329.59014892578125\n",
      "Eval_MinReturn : -342.7080383300781\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -350.8572692871094\n",
      "Train_StdReturn : 21.22004508972168\n",
      "Train_MaxReturn : -330.0321960449219\n",
      "Train_MinReturn : -385.3763732910156\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 21708\n",
      "TimeSinceStart : 216.80542373657227\n",
      "Training Loss : 0.18067549169063568\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -340.7924499511719\n",
      "Eval_StdReturn : 22.341278076171875\n",
      "Eval_MaxReturn : -318.451171875\n",
      "Eval_MinReturn : -363.13372802734375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -357.69610595703125\n",
      "Train_StdReturn : 21.46193504333496\n",
      "Train_MaxReturn : -328.49896240234375\n",
      "Train_MinReturn : -387.3018798828125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 22512\n",
      "TimeSinceStart : 309.88412380218506\n",
      "Training Loss : 0.17192848026752472\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -326.0224914550781\n",
      "Eval_StdReturn : 13.301544189453125\n",
      "Eval_MaxReturn : -312.720947265625\n",
      "Eval_MinReturn : -339.32403564453125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -349.6567077636719\n",
      "Train_StdReturn : 15.557744979858398\n",
      "Train_MaxReturn : -330.5662536621094\n",
      "Train_MinReturn : -371.6898498535156\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 23316\n",
      "TimeSinceStart : 403.4208631515503\n",
      "Training Loss : 0.17284579575061798\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -350.98583984375\n",
      "Eval_StdReturn : 4.0789337158203125\n",
      "Eval_MaxReturn : -346.90692138671875\n",
      "Eval_MinReturn : -355.0647888183594\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -369.6312255859375\n",
      "Train_StdReturn : 6.7529168128967285\n",
      "Train_MaxReturn : -358.90814208984375\n",
      "Train_MinReturn : -376.7187805175781\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24120\n",
      "TimeSinceStart : 497.3317394256592\n",
      "Training Loss : 0.16737611591815948\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -345.5663146972656\n",
      "Eval_StdReturn : 29.80279541015625\n",
      "Eval_MaxReturn : -315.7635192871094\n",
      "Eval_MinReturn : -375.3691101074219\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -354.3750915527344\n",
      "Train_StdReturn : 1.6265939474105835\n",
      "Train_MaxReturn : -352.25201416015625\n",
      "Train_MinReturn : -356.6312255859375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24924\n",
      "TimeSinceStart : 590.4720339775085\n",
      "Training Loss : 0.16302186250686646\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -355.80670166015625\n",
      "Eval_StdReturn : 14.852218627929688\n",
      "Eval_MaxReturn : -340.9544982910156\n",
      "Eval_MinReturn : -370.658935546875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -358.5975036621094\n",
      "Train_StdReturn : 42.51631164550781\n",
      "Train_MaxReturn : -318.5345153808594\n",
      "Train_MinReturn : -429.47735595703125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25728\n",
      "TimeSinceStart : 684.2257497310638\n",
      "Training Loss : 0.16142623126506805\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -335.96685791015625\n",
      "Eval_StdReturn : 13.071945190429688\n",
      "Eval_MaxReturn : -322.8948974609375\n",
      "Eval_MinReturn : -349.0387878417969\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -356.2740478515625\n",
      "Train_StdReturn : 18.450469970703125\n",
      "Train_MaxReturn : -337.0391540527344\n",
      "Train_MinReturn : -384.6109924316406\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 26532\n",
      "TimeSinceStart : 772.644992351532\n",
      "Training Loss : 0.15963496267795563\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -344.4780578613281\n",
      "Eval_StdReturn : 4.287261962890625\n",
      "Eval_MaxReturn : -340.1907958984375\n",
      "Eval_MinReturn : -348.76531982421875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -346.55712890625\n",
      "Train_StdReturn : 36.02635955810547\n",
      "Train_MaxReturn : -302.5901184082031\n",
      "Train_MinReturn : -389.5998840332031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 27336\n",
      "TimeSinceStart : 866.3358945846558\n",
      "Training Loss : 0.16002023220062256\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -315.488037109375\n",
      "Eval_StdReturn : 9.251785278320312\n",
      "Eval_MaxReturn : -306.2362365722656\n",
      "Eval_MinReturn : -324.73980712890625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -350.2960510253906\n",
      "Train_StdReturn : 32.50069046020508\n",
      "Train_MaxReturn : -312.0355224609375\n",
      "Train_MinReturn : -386.20068359375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28140\n",
      "TimeSinceStart : 960.568460226059\n",
      "Training Loss : 0.15441715717315674\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -364.1294250488281\n",
      "Eval_StdReturn : 16.879119873046875\n",
      "Eval_MaxReturn : -347.25030517578125\n",
      "Eval_MinReturn : -381.008544921875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -355.5211486816406\n",
      "Train_StdReturn : 34.29880905151367\n",
      "Train_MaxReturn : -310.40789794921875\n",
      "Train_MinReturn : -407.0006408691406\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28944\n",
      "TimeSinceStart : 1054.654339313507\n",
      "Training Loss : 0.1528368443250656\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -329.14886474609375\n",
      "Eval_StdReturn : 6.08599853515625\n",
      "Eval_MaxReturn : -323.0628662109375\n",
      "Eval_MinReturn : -335.23486328125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -356.5237731933594\n",
      "Train_StdReturn : 24.624406814575195\n",
      "Train_MaxReturn : -321.2793884277344\n",
      "Train_MinReturn : -387.5995788574219\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 29748\n",
      "TimeSinceStart : 1145.3496832847595\n",
      "Training Loss : 0.15074586868286133\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -334.1534729003906\n",
      "Eval_StdReturn : 5.85406494140625\n",
      "Eval_MaxReturn : -328.2994079589844\n",
      "Eval_MinReturn : -340.0075378417969\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -345.06536865234375\n",
      "Train_StdReturn : 42.46950912475586\n",
      "Train_MaxReturn : -301.93914794921875\n",
      "Train_MinReturn : -414.669921875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30552\n",
      "TimeSinceStart : 1229.9415373802185\n",
      "Training Loss : 0.15385979413986206\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -376.81842041015625\n",
      "Eval_StdReturn : 5.7429351806640625\n",
      "Eval_MaxReturn : -371.0754699707031\n",
      "Eval_MinReturn : -382.56134033203125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -344.564453125\n",
      "Train_StdReturn : 22.959848403930664\n",
      "Train_MaxReturn : -318.23358154296875\n",
      "Train_MinReturn : -378.37786865234375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 31356\n",
      "TimeSinceStart : 1313.7434241771698\n",
      "Training Loss : 0.1515863984823227\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q4_reacher_horizon30 --env_name reacher-cs285-v0 \\\n",
    "--add_sl_noise --mpc_horizon 30 --num_agent_train_steps_per_iter 1000 --video_log_freq -1 --batch_size 800 --n_iter 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_numseq100_reacher-cs285-v0_03-11-2020_19-16-19 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_numseq100_reacher-cs285-v0_03-11-2020_19-16-19\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20100 / 20000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -628.150634765625\n",
      "Eval_StdReturn : 158.26876831054688\n",
      "Eval_MaxReturn : -469.88189697265625\n",
      "Eval_MinReturn : -786.41943359375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1887.6396484375\n",
      "Train_StdReturn : 406.19140625\n",
      "Train_MaxReturn : -943.790283203125\n",
      "Train_MinReturn : -2592.39208984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 15.154404640197754\n",
      "Training Loss : 0.19842225313186646\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -331.74432373046875\n",
      "Eval_StdReturn : 2.4138031005859375\n",
      "Eval_MaxReturn : -329.33050537109375\n",
      "Eval_MinReturn : -334.1581115722656\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -494.3651428222656\n",
      "Train_StdReturn : 82.47954559326172\n",
      "Train_MaxReturn : -390.1324462890625\n",
      "Train_MinReturn : -620.4842529296875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20904\n",
      "TimeSinceStart : 41.30268740653992\n",
      "Training Loss : 0.1829935759305954\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -309.34808349609375\n",
      "Eval_StdReturn : 3.1488800048828125\n",
      "Eval_MaxReturn : -306.19921875\n",
      "Eval_MinReturn : -312.4969787597656\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -323.2372741699219\n",
      "Train_StdReturn : 19.84860610961914\n",
      "Train_MaxReturn : -307.814697265625\n",
      "Train_MinReturn : -357.19403076171875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 21708\n",
      "TimeSinceStart : 67.18828558921814\n",
      "Training Loss : 0.1731126755475998\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -285.81591796875\n",
      "Eval_StdReturn : 9.807998657226562\n",
      "Eval_MaxReturn : -276.0079040527344\n",
      "Eval_MinReturn : -295.6239013671875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -299.579345703125\n",
      "Train_StdReturn : 13.69468879699707\n",
      "Train_MaxReturn : -281.62249755859375\n",
      "Train_MinReturn : -315.8635559082031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 22512\n",
      "TimeSinceStart : 93.20649600028992\n",
      "Training Loss : 0.1706176996231079\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -293.1827697753906\n",
      "Eval_StdReturn : 15.922332763671875\n",
      "Eval_MaxReturn : -277.26043701171875\n",
      "Eval_MinReturn : -309.1051025390625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -350.8126220703125\n",
      "Train_StdReturn : 41.0858154296875\n",
      "Train_MaxReturn : -309.5393371582031\n",
      "Train_MinReturn : -412.94659423828125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 23316\n",
      "TimeSinceStart : 119.28423190116882\n",
      "Training Loss : 0.16476066410541534\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -307.5599365234375\n",
      "Eval_StdReturn : 16.073684692382812\n",
      "Eval_MaxReturn : -291.4862365722656\n",
      "Eval_MinReturn : -323.63360595703125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -285.9750671386719\n",
      "Train_StdReturn : 11.574723243713379\n",
      "Train_MaxReturn : -274.2267761230469\n",
      "Train_MinReturn : -303.75885009765625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24120\n",
      "TimeSinceStart : 145.2773277759552\n",
      "Training Loss : 0.17007099092006683\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -309.0008544921875\n",
      "Eval_StdReturn : 1.8366241455078125\n",
      "Eval_MaxReturn : -307.1642150878906\n",
      "Eval_MinReturn : -310.83746337890625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -292.5396728515625\n",
      "Train_StdReturn : 24.176898956298828\n",
      "Train_MaxReturn : -260.2302551269531\n",
      "Train_MinReturn : -327.89501953125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24924\n",
      "TimeSinceStart : 171.2418990135193\n",
      "Training Loss : 0.16798855364322662\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -316.61676025390625\n",
      "Eval_StdReturn : 27.395660400390625\n",
      "Eval_MaxReturn : -289.2210998535156\n",
      "Eval_MinReturn : -344.0124206542969\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -309.0107116699219\n",
      "Train_StdReturn : 21.405227661132812\n",
      "Train_MaxReturn : -277.7615051269531\n",
      "Train_MinReturn : -334.8873291015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25728\n",
      "TimeSinceStart : 197.3052694797516\n",
      "Training Loss : 0.1729455143213272\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -309.8210754394531\n",
      "Eval_StdReturn : 18.15777587890625\n",
      "Eval_MaxReturn : -291.6632995605469\n",
      "Eval_MinReturn : -327.9788513183594\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -300.5285949707031\n",
      "Train_StdReturn : 24.293167114257812\n",
      "Train_MaxReturn : -273.62371826171875\n",
      "Train_MinReturn : -338.2450866699219\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 26532\n",
      "TimeSinceStart : 223.39714813232422\n",
      "Training Loss : 0.158039391040802\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -306.71282958984375\n",
      "Eval_StdReturn : 12.4449462890625\n",
      "Eval_MaxReturn : -294.26788330078125\n",
      "Eval_MinReturn : -319.15777587890625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -311.92919921875\n",
      "Train_StdReturn : 28.071269989013672\n",
      "Train_MaxReturn : -276.24884033203125\n",
      "Train_MinReturn : -354.1264953613281\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 27336\n",
      "TimeSinceStart : 249.46776223182678\n",
      "Training Loss : 0.1586359292268753\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -326.84100341796875\n",
      "Eval_StdReturn : 22.027236938476562\n",
      "Eval_MaxReturn : -304.81378173828125\n",
      "Eval_MinReturn : -348.8682556152344\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -314.0467834472656\n",
      "Train_StdReturn : 36.39754104614258\n",
      "Train_MaxReturn : -285.60418701171875\n",
      "Train_MinReturn : -376.412353515625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28140\n",
      "TimeSinceStart : 275.4839491844177\n",
      "Training Loss : 0.15365451574325562\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -307.77239990234375\n",
      "Eval_StdReturn : 0.2012481689453125\n",
      "Eval_MaxReturn : -307.5711364746094\n",
      "Eval_MinReturn : -307.9736328125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -318.9835510253906\n",
      "Train_StdReturn : 10.138961791992188\n",
      "Train_MaxReturn : -301.6360168457031\n",
      "Train_MinReturn : -326.1086730957031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28944\n",
      "TimeSinceStart : 301.7171251773834\n",
      "Training Loss : 0.1580372303724289\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -311.74267578125\n",
      "Eval_StdReturn : 6.6377716064453125\n",
      "Eval_MaxReturn : -305.1048889160156\n",
      "Eval_MinReturn : -318.38043212890625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -305.79779052734375\n",
      "Train_StdReturn : 31.0908260345459\n",
      "Train_MaxReturn : -269.0257263183594\n",
      "Train_MinReturn : -338.5694885253906\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 29748\n",
      "TimeSinceStart : 327.8223602771759\n",
      "Training Loss : 0.1523473858833313\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -305.063720703125\n",
      "Eval_StdReturn : 21.404937744140625\n",
      "Eval_MaxReturn : -283.6587829589844\n",
      "Eval_MinReturn : -326.4686584472656\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -328.89984130859375\n",
      "Train_StdReturn : 12.820296287536621\n",
      "Train_MaxReturn : -308.2500915527344\n",
      "Train_MinReturn : -343.4670104980469\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30552\n",
      "TimeSinceStart : 353.9657778739929\n",
      "Training Loss : 0.15214215219020844\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -331.84765625\n",
      "Eval_StdReturn : 2.1074981689453125\n",
      "Eval_MaxReturn : -329.74017333984375\n",
      "Eval_MinReturn : -333.9551696777344\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -318.5672607421875\n",
      "Train_StdReturn : 28.03188705444336\n",
      "Train_MaxReturn : -279.31396484375\n",
      "Train_MinReturn : -358.3753662109375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 31356\n",
      "TimeSinceStart : 380.7327845096588\n",
      "Training Loss : 0.1481190174818039\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q4_reacher_numseq100 --env_name reacher-cs285-v0 \\\n",
    "--add_sl_noise --mpc_horizon 10 --num_agent_train_steps_per_iter 1000 --batch_size 800 \\\n",
    "--n_iter 15 --mpc_num_action_sequences 100 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_numseq1000_reacher-cs285-v0_03-11-2020_19-22-42 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_numseq1000_reacher-cs285-v0_03-11-2020_19-22-42\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20100 / 20000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -457.7017517089844\n",
      "Eval_StdReturn : 8.054107666015625\n",
      "Eval_MaxReturn : -449.64764404296875\n",
      "Eval_MinReturn : -465.755859375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1887.6396484375\n",
      "Train_StdReturn : 406.19140625\n",
      "Train_MaxReturn : -943.790283203125\n",
      "Train_MinReturn : -2592.39208984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 18.959158897399902\n",
      "Training Loss : 0.19842225313186646\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -297.8695068359375\n",
      "Eval_StdReturn : 24.376541137695312\n",
      "Eval_MaxReturn : -273.49298095703125\n",
      "Eval_MinReturn : -322.2460632324219\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -444.02178955078125\n",
      "Train_StdReturn : 47.03759002685547\n",
      "Train_MaxReturn : -379.1318054199219\n",
      "Train_MinReturn : -499.10748291015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20904\n",
      "TimeSinceStart : 55.947349309921265\n",
      "Training Loss : 0.18720455467700958\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -276.3612976074219\n",
      "Eval_StdReturn : 7.9541015625\n",
      "Eval_MaxReturn : -268.4071960449219\n",
      "Eval_MinReturn : -284.3153991699219\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -280.545654296875\n",
      "Train_StdReturn : 22.182430267333984\n",
      "Train_MaxReturn : -257.99078369140625\n",
      "Train_MinReturn : -315.3694152832031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 21708\n",
      "TimeSinceStart : 90.78923058509827\n",
      "Training Loss : 0.1748189777135849\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -264.94451904296875\n",
      "Eval_StdReturn : 10.71624755859375\n",
      "Eval_MaxReturn : -254.228271484375\n",
      "Eval_MinReturn : -275.6607666015625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -267.7628173828125\n",
      "Train_StdReturn : 9.621484756469727\n",
      "Train_MaxReturn : -252.86708068847656\n",
      "Train_MinReturn : -278.7337646484375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 22512\n",
      "TimeSinceStart : 124.97815942764282\n",
      "Training Loss : 0.17309091985225677\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -268.2654113769531\n",
      "Eval_StdReturn : 1.68914794921875\n",
      "Eval_MaxReturn : -266.5762634277344\n",
      "Eval_MinReturn : -269.9545593261719\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -262.01776123046875\n",
      "Train_StdReturn : 7.312418460845947\n",
      "Train_MaxReturn : -252.1278533935547\n",
      "Train_MinReturn : -272.3351135253906\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 23316\n",
      "TimeSinceStart : 160.77095293998718\n",
      "Training Loss : 0.16623139381408691\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -295.28009033203125\n",
      "Eval_StdReturn : 22.98541259765625\n",
      "Eval_MaxReturn : -272.294677734375\n",
      "Eval_MinReturn : -318.2655029296875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -283.9081115722656\n",
      "Train_StdReturn : 17.80360984802246\n",
      "Train_MaxReturn : -265.34619140625\n",
      "Train_MinReturn : -312.1306457519531\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24120\n",
      "TimeSinceStart : 194.77271223068237\n",
      "Training Loss : 0.17054766416549683\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -278.2667541503906\n",
      "Eval_StdReturn : 22.884010314941406\n",
      "Eval_MaxReturn : -255.3827362060547\n",
      "Eval_MinReturn : -301.1507568359375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -274.2874755859375\n",
      "Train_StdReturn : 29.620885848999023\n",
      "Train_MaxReturn : -240.19000244140625\n",
      "Train_MinReturn : -307.4902038574219\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24924\n",
      "TimeSinceStart : 229.3287603855133\n",
      "Training Loss : 0.16058547794818878\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -270.4102783203125\n",
      "Eval_StdReturn : 30.310501098632812\n",
      "Eval_MaxReturn : -240.09976196289062\n",
      "Eval_MinReturn : -300.72076416015625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -323.2470703125\n",
      "Train_StdReturn : 78.0498275756836\n",
      "Train_MaxReturn : -264.8335266113281\n",
      "Train_MinReturn : -457.31146240234375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25728\n",
      "TimeSinceStart : 263.8821346759796\n",
      "Training Loss : 0.15978194773197174\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -274.6656799316406\n",
      "Eval_StdReturn : 24.587852478027344\n",
      "Eval_MaxReturn : -250.0778350830078\n",
      "Eval_MinReturn : -299.2535400390625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -271.0976257324219\n",
      "Train_StdReturn : 12.068183898925781\n",
      "Train_MaxReturn : -250.27101135253906\n",
      "Train_MinReturn : -279.2071228027344\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 26532\n",
      "TimeSinceStart : 298.15254187583923\n",
      "Training Loss : 0.1522752344608307\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -252.12786865234375\n",
      "Eval_StdReturn : 17.130271911621094\n",
      "Eval_MaxReturn : -234.9976043701172\n",
      "Eval_MinReturn : -269.2581481933594\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -268.02734375\n",
      "Train_StdReturn : 9.2474946975708\n",
      "Train_MaxReturn : -256.4500732421875\n",
      "Train_MinReturn : -279.96246337890625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 27336\n",
      "TimeSinceStart : 330.82971811294556\n",
      "Training Loss : 0.16129101812839508\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -307.3219299316406\n",
      "Eval_StdReturn : 19.429443359375\n",
      "Eval_MaxReturn : -287.8924865722656\n",
      "Eval_MinReturn : -326.7513732910156\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -286.74652099609375\n",
      "Train_StdReturn : 20.659486770629883\n",
      "Train_MaxReturn : -274.1910095214844\n",
      "Train_MinReturn : -322.52191162109375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28140\n",
      "TimeSinceStart : 364.8977437019348\n",
      "Training Loss : 0.15147119760513306\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -274.419677734375\n",
      "Eval_StdReturn : 11.015213012695312\n",
      "Eval_MaxReturn : -263.40447998046875\n",
      "Eval_MinReturn : -285.4349060058594\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -253.42010498046875\n",
      "Train_StdReturn : 13.214412689208984\n",
      "Train_MaxReturn : -236.5567626953125\n",
      "Train_MinReturn : -270.904541015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28944\n",
      "TimeSinceStart : 398.6510326862335\n",
      "Training Loss : 0.15113681554794312\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -260.28790283203125\n",
      "Eval_StdReturn : 6.776023864746094\n",
      "Eval_MaxReturn : -253.5118865966797\n",
      "Eval_MinReturn : -267.0639343261719\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -265.4255065917969\n",
      "Train_StdReturn : 12.662282943725586\n",
      "Train_MaxReturn : -248.00424194335938\n",
      "Train_MinReturn : -279.3931884765625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 29748\n",
      "TimeSinceStart : 430.7370665073395\n",
      "Training Loss : 0.14724218845367432\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -243.89047241210938\n",
      "Eval_StdReturn : 21.24152374267578\n",
      "Eval_MaxReturn : -222.64894104003906\n",
      "Eval_MinReturn : -265.1319885253906\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -270.0223693847656\n",
      "Train_StdReturn : 13.030344009399414\n",
      "Train_MaxReturn : -252.59799194335938\n",
      "Train_MinReturn : -289.07177734375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30552\n",
      "TimeSinceStart : 463.36039686203003\n",
      "Training Loss : 0.1467467099428177\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -254.98300170898438\n",
      "Eval_StdReturn : 0.41729736328125\n",
      "Eval_MaxReturn : -254.56570434570312\n",
      "Eval_MinReturn : -255.40029907226562\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -272.68450927734375\n",
      "Train_StdReturn : 9.22579288482666\n",
      "Train_MaxReturn : -261.1894226074219\n",
      "Train_MinReturn : -286.9614562988281\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 31356\n",
      "TimeSinceStart : 496.9091765880585\n",
      "Training Loss : 0.14277349412441254\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q4_reacher_numseq1000 --env_name reacher-cs285-v0 \\\n",
    "--add_sl_noise --mpc_horizon 10 --num_agent_train_steps_per_iter 1000 --batch_size 800 \\\n",
    "--n_iter 15 --mpc_num_action_sequences 1000 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble1_reacher-cs285-v0_03-11-2020_19-31-02 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble1_reacher-cs285-v0_03-11-2020_19-31-02\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20100 / 20000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -502.006591796875\n",
      "Eval_StdReturn : 73.74681091308594\n",
      "Eval_MaxReturn : -428.2597961425781\n",
      "Eval_MinReturn : -575.75341796875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1887.6396484375\n",
      "Train_StdReturn : 406.19140625\n",
      "Train_MaxReturn : -943.790283203125\n",
      "Train_MinReturn : -2592.39208984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 8.308911323547363\n",
      "Training Loss : 0.19885388016700745\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -325.19921875\n",
      "Eval_StdReturn : 5.8654022216796875\n",
      "Eval_MaxReturn : -319.33380126953125\n",
      "Eval_MinReturn : -331.0646057128906\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -459.64337158203125\n",
      "Train_StdReturn : 40.16130065917969\n",
      "Train_MaxReturn : -403.0946044921875\n",
      "Train_MinReturn : -515.4153442382812\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20904\n",
      "TimeSinceStart : 20.453221321105957\n",
      "Training Loss : 0.19088493287563324\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -348.94171142578125\n",
      "Eval_StdReturn : 25.449630737304688\n",
      "Eval_MaxReturn : -323.4920654296875\n",
      "Eval_MinReturn : -374.3913269042969\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -282.8724365234375\n",
      "Train_StdReturn : 11.720001220703125\n",
      "Train_MaxReturn : -267.64288330078125\n",
      "Train_MinReturn : -295.51287841796875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 21708\n",
      "TimeSinceStart : 32.11016273498535\n",
      "Training Loss : 0.17338350415229797\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -290.95465087890625\n",
      "Eval_StdReturn : 6.53131103515625\n",
      "Eval_MaxReturn : -284.42333984375\n",
      "Eval_MinReturn : -297.4859619140625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -275.47467041015625\n",
      "Train_StdReturn : 5.017876148223877\n",
      "Train_MaxReturn : -268.4682922363281\n",
      "Train_MinReturn : -282.46502685546875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 22512\n",
      "TimeSinceStart : 44.37668561935425\n",
      "Training Loss : 0.16717217862606049\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -272.9677734375\n",
      "Eval_StdReturn : 5.18096923828125\n",
      "Eval_MaxReturn : -267.78680419921875\n",
      "Eval_MinReturn : -278.14874267578125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -297.91259765625\n",
      "Train_StdReturn : 26.859107971191406\n",
      "Train_MaxReturn : -262.4038391113281\n",
      "Train_MinReturn : -332.887939453125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 23316\n",
      "TimeSinceStart : 56.65088224411011\n",
      "Training Loss : 0.162862166762352\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -270.1546325683594\n",
      "Eval_StdReturn : 35.180267333984375\n",
      "Eval_MaxReturn : -234.974365234375\n",
      "Eval_MinReturn : -305.33489990234375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -309.0554504394531\n",
      "Train_StdReturn : 47.47665786743164\n",
      "Train_MaxReturn : -273.1124267578125\n",
      "Train_MinReturn : -390.2972412109375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24120\n",
      "TimeSinceStart : 68.86744236946106\n",
      "Training Loss : 0.17666728794574738\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -286.69696044921875\n",
      "Eval_StdReturn : 8.1231689453125\n",
      "Eval_MaxReturn : -278.57379150390625\n",
      "Eval_MinReturn : -294.82012939453125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -254.32078552246094\n",
      "Train_StdReturn : 7.381165981292725\n",
      "Train_MaxReturn : -244.67929077148438\n",
      "Train_MinReturn : -262.996826171875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24924\n",
      "TimeSinceStart : 80.65721321105957\n",
      "Training Loss : 0.1571337729692459\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -296.74176025390625\n",
      "Eval_StdReturn : 8.164108276367188\n",
      "Eval_MaxReturn : -288.5776672363281\n",
      "Eval_MinReturn : -304.9058837890625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -284.31890869140625\n",
      "Train_StdReturn : 14.410905838012695\n",
      "Train_MaxReturn : -266.3224792480469\n",
      "Train_MinReturn : -305.9836730957031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25728\n",
      "TimeSinceStart : 92.80195045471191\n",
      "Training Loss : 0.16031481325626373\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -288.61004638671875\n",
      "Eval_StdReturn : 38.66572570800781\n",
      "Eval_MaxReturn : -249.94430541992188\n",
      "Eval_MinReturn : -327.2757568359375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -309.41827392578125\n",
      "Train_StdReturn : 52.95882034301758\n",
      "Train_MaxReturn : -257.57891845703125\n",
      "Train_MinReturn : -385.4588317871094\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 26532\n",
      "TimeSinceStart : 104.47192192077637\n",
      "Training Loss : 0.1562580019235611\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -259.9698791503906\n",
      "Eval_StdReturn : 16.908348083496094\n",
      "Eval_MaxReturn : -243.06153869628906\n",
      "Eval_MinReturn : -276.87823486328125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -275.0456237792969\n",
      "Train_StdReturn : 18.295249938964844\n",
      "Train_MaxReturn : -244.85528564453125\n",
      "Train_MinReturn : -294.17669677734375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 27336\n",
      "TimeSinceStart : 116.13775396347046\n",
      "Training Loss : 0.1565430611371994\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -280.97283935546875\n",
      "Eval_StdReturn : 15.00830078125\n",
      "Eval_MaxReturn : -265.96453857421875\n",
      "Eval_MinReturn : -295.98114013671875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -272.6365661621094\n",
      "Train_StdReturn : 26.253921508789062\n",
      "Train_MaxReturn : -242.3038787841797\n",
      "Train_MinReturn : -314.5238952636719\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28140\n",
      "TimeSinceStart : 127.9375536441803\n",
      "Training Loss : 0.15143738687038422\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -266.00732421875\n",
      "Eval_StdReturn : 9.77545166015625\n",
      "Eval_MaxReturn : -256.23187255859375\n",
      "Eval_MinReturn : -275.78277587890625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -262.9161071777344\n",
      "Train_StdReturn : 14.54343318939209\n",
      "Train_MaxReturn : -243.08265686035156\n",
      "Train_MinReturn : -284.0318298339844\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28944\n",
      "TimeSinceStart : 139.86964797973633\n",
      "Training Loss : 0.15010970830917358\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -275.34503173828125\n",
      "Eval_StdReturn : 1.2296295166015625\n",
      "Eval_MaxReturn : -274.1153869628906\n",
      "Eval_MinReturn : -276.57464599609375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -278.7773742675781\n",
      "Train_StdReturn : 18.65764617919922\n",
      "Train_MaxReturn : -250.6983184814453\n",
      "Train_MinReturn : -302.23248291015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 29748\n",
      "TimeSinceStart : 152.22362971305847\n",
      "Training Loss : 0.15100543200969696\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -296.73779296875\n",
      "Eval_StdReturn : 30.1337890625\n",
      "Eval_MaxReturn : -266.60400390625\n",
      "Eval_MinReturn : -326.87158203125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -260.9761962890625\n",
      "Train_StdReturn : 14.387847900390625\n",
      "Train_MaxReturn : -239.59042358398438\n",
      "Train_MinReturn : -278.05322265625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30552\n",
      "TimeSinceStart : 164.330064535141\n",
      "Training Loss : 0.14969849586486816\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -274.0728454589844\n",
      "Eval_StdReturn : 2.59710693359375\n",
      "Eval_MaxReturn : -271.4757385253906\n",
      "Eval_MinReturn : -276.6699523925781\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -265.36151123046875\n",
      "Train_StdReturn : 5.319921016693115\n",
      "Train_MaxReturn : -258.3741455078125\n",
      "Train_MinReturn : -273.30059814453125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 31356\n",
      "TimeSinceStart : 176.67613315582275\n",
      "Training Loss : 0.1490183174610138\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q4_reacher_ensemble1 --env_name reacher-cs285-v0 \\\n",
    "--ensemble_size 1 --add_sl_noise --mpc_horizon 10 --num_agent_train_steps_per_iter 1000 \\\n",
    "--batch_size 800 --n_iter 15 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble3_reacher-cs285-v0_03-11-2020_19-34-02 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble3_reacher-cs285-v0_03-11-2020_19-34-02\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20100 / 20000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -457.7017517089844\n",
      "Eval_StdReturn : 8.054107666015625\n",
      "Eval_MaxReturn : -449.64764404296875\n",
      "Eval_MinReturn : -465.755859375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1887.6396484375\n",
      "Train_StdReturn : 406.19140625\n",
      "Train_MaxReturn : -943.790283203125\n",
      "Train_MinReturn : -2592.39208984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 18.803444623947144\n",
      "Training Loss : 0.19842225313186646\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -297.8695068359375\n",
      "Eval_StdReturn : 24.376541137695312\n",
      "Eval_MaxReturn : -273.49298095703125\n",
      "Eval_MinReturn : -322.2460632324219\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -444.02178955078125\n",
      "Train_StdReturn : 47.03759002685547\n",
      "Train_MaxReturn : -379.1318054199219\n",
      "Train_MinReturn : -499.10748291015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20904\n",
      "TimeSinceStart : 51.85591983795166\n",
      "Training Loss : 0.18720455467700958\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -276.3612976074219\n",
      "Eval_StdReturn : 7.9541015625\n",
      "Eval_MaxReturn : -268.4071960449219\n",
      "Eval_MinReturn : -284.3153991699219\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -280.545654296875\n",
      "Train_StdReturn : 22.182430267333984\n",
      "Train_MaxReturn : -257.99078369140625\n",
      "Train_MinReturn : -315.3694152832031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 21708\n",
      "TimeSinceStart : 86.24319744110107\n",
      "Training Loss : 0.1748189777135849\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -264.94451904296875\n",
      "Eval_StdReturn : 10.71624755859375\n",
      "Eval_MaxReturn : -254.228271484375\n",
      "Eval_MinReturn : -275.6607666015625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -267.7628173828125\n",
      "Train_StdReturn : 9.621484756469727\n",
      "Train_MaxReturn : -252.86708068847656\n",
      "Train_MinReturn : -278.7337646484375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 22512\n",
      "TimeSinceStart : 120.82827639579773\n",
      "Training Loss : 0.17309091985225677\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -268.2654113769531\n",
      "Eval_StdReturn : 1.68914794921875\n",
      "Eval_MaxReturn : -266.5762634277344\n",
      "Eval_MinReturn : -269.9545593261719\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -262.01776123046875\n",
      "Train_StdReturn : 7.312418460845947\n",
      "Train_MaxReturn : -252.1278533935547\n",
      "Train_MinReturn : -272.3351135253906\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 23316\n",
      "TimeSinceStart : 156.12466835975647\n",
      "Training Loss : 0.16623139381408691\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -295.28009033203125\n",
      "Eval_StdReturn : 22.98541259765625\n",
      "Eval_MaxReturn : -272.294677734375\n",
      "Eval_MinReturn : -318.2655029296875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -283.9081115722656\n",
      "Train_StdReturn : 17.80360984802246\n",
      "Train_MaxReturn : -265.34619140625\n",
      "Train_MinReturn : -312.1306457519531\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24120\n",
      "TimeSinceStart : 190.85320520401\n",
      "Training Loss : 0.17054766416549683\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -278.2667541503906\n",
      "Eval_StdReturn : 22.884010314941406\n",
      "Eval_MaxReturn : -255.3827362060547\n",
      "Eval_MinReturn : -301.1507568359375\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -274.2874755859375\n",
      "Train_StdReturn : 29.620885848999023\n",
      "Train_MaxReturn : -240.19000244140625\n",
      "Train_MinReturn : -307.4902038574219\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24924\n",
      "TimeSinceStart : 225.59226322174072\n",
      "Training Loss : 0.16058547794818878\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -270.4102783203125\n",
      "Eval_StdReturn : 30.310501098632812\n",
      "Eval_MaxReturn : -240.09976196289062\n",
      "Eval_MinReturn : -300.72076416015625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -323.2470703125\n",
      "Train_StdReturn : 78.0498275756836\n",
      "Train_MaxReturn : -264.8335266113281\n",
      "Train_MinReturn : -457.31146240234375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25728\n",
      "TimeSinceStart : 260.4298777580261\n",
      "Training Loss : 0.15978194773197174\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -274.6656799316406\n",
      "Eval_StdReturn : 24.587852478027344\n",
      "Eval_MaxReturn : -250.0778350830078\n",
      "Eval_MinReturn : -299.2535400390625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -271.0976257324219\n",
      "Train_StdReturn : 12.068183898925781\n",
      "Train_MaxReturn : -250.27101135253906\n",
      "Train_MinReturn : -279.2071228027344\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 26532\n",
      "TimeSinceStart : 295.082528591156\n",
      "Training Loss : 0.1522752344608307\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -252.12786865234375\n",
      "Eval_StdReturn : 17.130271911621094\n",
      "Eval_MaxReturn : -234.9976043701172\n",
      "Eval_MinReturn : -269.2581481933594\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -268.02734375\n",
      "Train_StdReturn : 9.2474946975708\n",
      "Train_MaxReturn : -256.4500732421875\n",
      "Train_MinReturn : -279.96246337890625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 27336\n",
      "TimeSinceStart : 329.8795487880707\n",
      "Training Loss : 0.16129101812839508\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -307.3219299316406\n",
      "Eval_StdReturn : 19.429443359375\n",
      "Eval_MaxReturn : -287.8924865722656\n",
      "Eval_MinReturn : -326.7513732910156\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -286.74652099609375\n",
      "Train_StdReturn : 20.659486770629883\n",
      "Train_MaxReturn : -274.1910095214844\n",
      "Train_MinReturn : -322.52191162109375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28140\n",
      "TimeSinceStart : 364.5799572467804\n",
      "Training Loss : 0.15147119760513306\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -274.419677734375\n",
      "Eval_StdReturn : 11.015213012695312\n",
      "Eval_MaxReturn : -263.40447998046875\n",
      "Eval_MinReturn : -285.4349060058594\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -253.42010498046875\n",
      "Train_StdReturn : 13.214412689208984\n",
      "Train_MaxReturn : -236.5567626953125\n",
      "Train_MinReturn : -270.904541015625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28944\n",
      "TimeSinceStart : 399.28810262680054\n",
      "Training Loss : 0.15113681554794312\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -260.28790283203125\n",
      "Eval_StdReturn : 6.776023864746094\n",
      "Eval_MaxReturn : -253.5118865966797\n",
      "Eval_MinReturn : -267.0639343261719\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -265.4255065917969\n",
      "Train_StdReturn : 12.662282943725586\n",
      "Train_MaxReturn : -248.00424194335938\n",
      "Train_MinReturn : -279.3931884765625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 29748\n",
      "TimeSinceStart : 434.3495399951935\n",
      "Training Loss : 0.14724218845367432\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -243.89047241210938\n",
      "Eval_StdReturn : 21.24152374267578\n",
      "Eval_MaxReturn : -222.64894104003906\n",
      "Eval_MinReturn : -265.1319885253906\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -270.0223693847656\n",
      "Train_StdReturn : 13.030344009399414\n",
      "Train_MaxReturn : -252.59799194335938\n",
      "Train_MinReturn : -289.07177734375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30552\n",
      "TimeSinceStart : 469.3263659477234\n",
      "Training Loss : 0.1467467099428177\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -254.98300170898438\n",
      "Eval_StdReturn : 0.41729736328125\n",
      "Eval_MaxReturn : -254.56570434570312\n",
      "Eval_MinReturn : -255.40029907226562\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -272.68450927734375\n",
      "Train_StdReturn : 9.22579288482666\n",
      "Train_MaxReturn : -261.1894226074219\n",
      "Train_MinReturn : -286.9614562988281\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 31356\n",
      "TimeSinceStart : 504.10421919822693\n",
      "Training Loss : 0.14277349412441254\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q4_reacher_ensemble3 --env_name reacher-cs285-v0 \\\n",
    "--ensemble_size 3 --add_sl_noise --mpc_horizon 10 --num_agent_train_steps_per_iter 1000 \\\n",
    "--batch_size 800 --n_iter 15 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LOGGING TO:  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble5_reacher-cs285-v0_03-11-2020_19-42-29 \n",
      "\n",
      "\n",
      "\n",
      "########################\n",
      "logging outputs to  /home/tomas/Documents/cs285/homework_fall2020/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble5_reacher-cs285-v0_03-11-2020_19-42-29\n",
      "########################\n",
      "Using GPU id 0\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     20100 / 20000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -378.93841552734375\n",
      "Eval_StdReturn : 19.162551879882812\n",
      "Eval_MaxReturn : -359.77587890625\n",
      "Eval_MinReturn : -398.1009826660156\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -1887.6396484375\n",
      "Train_StdReturn : 406.19140625\n",
      "Train_MaxReturn : -943.790283203125\n",
      "Train_MinReturn : -2592.39208984375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20100\n",
      "TimeSinceStart : 28.169100046157837\n",
      "Training Loss : 0.1979539692401886\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -269.75787353515625\n",
      "Eval_StdReturn : 11.96142578125\n",
      "Eval_MaxReturn : -257.79644775390625\n",
      "Eval_MinReturn : -281.71929931640625\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -461.6570739746094\n",
      "Train_StdReturn : 97.4911880493164\n",
      "Train_MaxReturn : -372.52960205078125\n",
      "Train_MinReturn : -626.5648193359375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 20904\n",
      "TimeSinceStart : 85.20027375221252\n",
      "Training Loss : 0.1858016699552536\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -254.61434936523438\n",
      "Eval_StdReturn : 9.887481689453125\n",
      "Eval_MaxReturn : -244.72686767578125\n",
      "Eval_MinReturn : -264.5018310546875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -264.3918762207031\n",
      "Train_StdReturn : 12.038915634155273\n",
      "Train_MaxReturn : -252.07078552246094\n",
      "Train_MinReturn : -283.19195556640625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 21708\n",
      "TimeSinceStart : 142.0510654449463\n",
      "Training Loss : 0.1748981773853302\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -253.2762451171875\n",
      "Eval_StdReturn : 2.2568435668945312\n",
      "Eval_MaxReturn : -251.01939392089844\n",
      "Eval_MinReturn : -255.5330810546875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -252.00396728515625\n",
      "Train_StdReturn : 12.560279846191406\n",
      "Train_MaxReturn : -231.88485717773438\n",
      "Train_MinReturn : -264.1184387207031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 22512\n",
      "TimeSinceStart : 199.15946078300476\n",
      "Training Loss : 0.17161168158054352\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -259.34600830078125\n",
      "Eval_StdReturn : 4.0989837646484375\n",
      "Eval_MaxReturn : -255.24703979492188\n",
      "Eval_MinReturn : -263.44500732421875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -258.21881103515625\n",
      "Train_StdReturn : 11.070230484008789\n",
      "Train_MaxReturn : -241.46551513671875\n",
      "Train_MinReturn : -271.43280029296875\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 23316\n",
      "TimeSinceStart : 256.42927408218384\n",
      "Training Loss : 0.1682989001274109\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -253.25592041015625\n",
      "Eval_StdReturn : 10.6358642578125\n",
      "Eval_MaxReturn : -242.62005615234375\n",
      "Eval_MinReturn : -263.89178466796875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -260.5913391113281\n",
      "Train_StdReturn : 24.71023178100586\n",
      "Train_MaxReturn : -236.59849548339844\n",
      "Train_MinReturn : -300.9891662597656\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24120\n",
      "TimeSinceStart : 313.51426553726196\n",
      "Training Loss : 0.16866600513458252\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -274.4276123046875\n",
      "Eval_StdReturn : 13.305404663085938\n",
      "Eval_MaxReturn : -261.1221923828125\n",
      "Eval_MinReturn : -287.7330017089844\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -255.42727661132812\n",
      "Train_StdReturn : 8.770039558410645\n",
      "Train_MaxReturn : -245.427734375\n",
      "Train_MinReturn : -264.19537353515625\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 24924\n",
      "TimeSinceStart : 371.00874376296997\n",
      "Training Loss : 0.16633723676204681\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -249.36212158203125\n",
      "Eval_StdReturn : 17.938438415527344\n",
      "Eval_MaxReturn : -231.42369079589844\n",
      "Eval_MinReturn : -267.3005676269531\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -254.45272827148438\n",
      "Train_StdReturn : 7.517704010009766\n",
      "Train_MaxReturn : -244.47618103027344\n",
      "Train_MinReturn : -262.4612731933594\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 25728\n",
      "TimeSinceStart : 428.35557079315186\n",
      "Training Loss : 0.15980279445648193\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -268.2703857421875\n",
      "Eval_StdReturn : 4.3696441650390625\n",
      "Eval_MaxReturn : -263.9007568359375\n",
      "Eval_MinReturn : -272.6400451660156\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -258.57952880859375\n",
      "Train_StdReturn : 15.79659366607666\n",
      "Train_MaxReturn : -243.80621337890625\n",
      "Train_MinReturn : -284.7008972167969\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 26532\n",
      "TimeSinceStart : 485.57893800735474\n",
      "Training Loss : 0.15866969525814056\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -238.4531707763672\n",
      "Eval_StdReturn : 1.2771148681640625\n",
      "Eval_MaxReturn : -237.17605590820312\n",
      "Eval_MinReturn : -239.73028564453125\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -255.81309509277344\n",
      "Train_StdReturn : 15.234175682067871\n",
      "Train_MaxReturn : -242.16998291015625\n",
      "Train_MinReturn : -281.26739501953125\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 27336\n",
      "TimeSinceStart : 542.0347697734833\n",
      "Training Loss : 0.158918559551239\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -259.81304931640625\n",
      "Eval_StdReturn : 12.046539306640625\n",
      "Eval_MaxReturn : -247.76651000976562\n",
      "Eval_MinReturn : -271.8595886230469\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -265.45892333984375\n",
      "Train_StdReturn : 12.342268943786621\n",
      "Train_MaxReturn : -248.8417205810547\n",
      "Train_MinReturn : -281.4935607910156\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28140\n",
      "TimeSinceStart : 593.6144449710846\n",
      "Training Loss : 0.15806742012500763\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -278.757080078125\n",
      "Eval_StdReturn : 5.6911468505859375\n",
      "Eval_MaxReturn : -273.0659484863281\n",
      "Eval_MinReturn : -284.4482421875\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -247.5282745361328\n",
      "Train_StdReturn : 13.522991180419922\n",
      "Train_MaxReturn : -224.37754821777344\n",
      "Train_MinReturn : -258.1026306152344\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 28944\n",
      "TimeSinceStart : 644.9467852115631\n",
      "Training Loss : 0.1540728509426117\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -255.60940551757812\n",
      "Eval_StdReturn : 5.09771728515625\n",
      "Eval_MaxReturn : -250.51168823242188\n",
      "Eval_MinReturn : -260.7071228027344\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -251.21180725097656\n",
      "Train_StdReturn : 1.9535239934921265\n",
      "Train_MaxReturn : -248.043212890625\n",
      "Train_MinReturn : -253.2771759033203\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 29748\n",
      "TimeSinceStart : 697.3340535163879\n",
      "Training Loss : 0.1528688371181488\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -242.1986846923828\n",
      "Eval_StdReturn : 10.319168090820312\n",
      "Eval_MaxReturn : -231.8795166015625\n",
      "Eval_MinReturn : -252.51785278320312\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -263.9807434082031\n",
      "Train_StdReturn : 6.805201530456543\n",
      "Train_MaxReturn : -252.4644775390625\n",
      "Train_MinReturn : -269.06243896484375\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 30552\n",
      "TimeSinceStart : 748.8167111873627\n",
      "Training Loss : 0.14770987629890442\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     804 / 800\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : -265.5775451660156\n",
      "Eval_StdReturn : 5.85223388671875\n",
      "Eval_MaxReturn : -259.7253112792969\n",
      "Eval_MinReturn : -271.4297790527344\n",
      "Eval_AverageEpLen : 201.0\n",
      "Train_AverageReturn : -259.3190002441406\n",
      "Train_StdReturn : 11.29131031036377\n",
      "Train_MaxReturn : -242.54869079589844\n",
      "Train_MinReturn : -273.5657043457031\n",
      "Train_AverageEpLen : 201.0\n",
      "Train_EnvstepsSoFar : 31356\n",
      "TimeSinceStart : 800.7579817771912\n",
      "Training Loss : 0.15015824139118195\n",
      "Initial_DataCollection_AverageReturn : -1887.6396484375\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ./run_hw4_mb.py --exp_name q4_reacher_ensemble5 --env_name reacher-cs285-v0 \\\n",
    "--ensemble_size 5 --add_sl_noise --mpc_horizon 10 --num_agent_train_steps_per_iter 1000 \\\n",
    "--batch_size 800 --n_iter 15 --video_log_freq -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
